{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nNotes:\\n- since only looking at 2012-15, can just do cross-val. Don't expect temporal differences\\n(as opposed to if training from 1950-2023, where causal differences in league)\\n- only care about ranking current prospects, not how metrics generalize to unseen prospects.\\nso no need for test set \\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Notes:\n",
    "- since only looking at 2012-15, can just do cross-val. Don't expect temporal differences\n",
    "(as opposed to if training from 1950-2023, where causal differences in league)\n",
    "- want to rank all prospects, so no test set \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"model_data/input_dataset.csv\", index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop targets and NFL production\n",
    "X = dataset.drop([\"Score\", \"Success\"] + ['num_seasons', 'GamesPlayed', 'GamesStarted', 'Plays', 'PositivePlays',\n",
    "       'NegativePlays', 'GP%', 'GS%', 'PosPlay%', 'NegPlay%', 'NeutPlay%'],axis=1)\n",
    "X[\"ProPosition\"] = X[\"ProPosition\"].astype(\"category\")\n",
    "X[\"IndyInvite\"] = X[\"IndyInvite\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return score and params\n",
    "def grid_search(model, X, y, param_grid, num_folds, eval_scoring_str):\n",
    "    clf = GridSearchCV(\n",
    "        model,\n",
    "        param_grid,\n",
    "        verbose=1,\n",
    "        cv=num_folds, \n",
    "        refit=True,\n",
    "        scoring=eval_scoring_str  #accuracy, neg_log_loss, roc_auc\n",
    "    )\n",
    "    clf.fit(X, y)\n",
    "    print(f\"{clf.best_score_}\")\n",
    "    print(f\"{clf.best_params_}\")\n",
    "    return clf\n",
    "\n",
    "def run_grid_search():\n",
    "    param_grid = {\"max_depth\":    [6, 4],\n",
    "              \"learning_rate\": [0.1],\n",
    "              \"n_estimators\": [100, 500, 600]\n",
    "            }\n",
    "    NUM_FOLDS=5\n",
    "    grid_search_xg = xgb.XGBRegressor(tree_method=\"hist\", enable_categorical=True, \n",
    "                                        objective='reg:squarederror')\n",
    "    grid_search_cv = grid_search(grid_search_xg, X, dataset['Score'], \n",
    "                                param_grid, num_folds=NUM_FOLDS, eval_scoring_str='neg_mean_squared_error')    # neg_mean_squared_error\n",
    "    grid_search_model = grid_search_cv.best_estimator_\n",
    "    grid_search_preds = cross_val_predict(grid_search_model, X, dataset['Score'], cv=X.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-07 13:52:01,022] A new study created in memory with name: no-name-54f33364-a79a-4c16-af7d-542f49eecd92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-07 13:52:03,896] Trial 0 finished with value: -0.06296795641091547 and parameters: {'max_depth': 9, 'learning_rate': 0.05625242735857511, 'n_estimators': 300, 'subsample': 0.2, 'min_child_weight': 3}. Best is trial 0 with value: -0.06296795641091547.\n",
      "[I 2024-04-07 13:52:07,757] Trial 1 finished with value: -0.05704431929763076 and parameters: {'max_depth': 5, 'learning_rate': 0.0160986838287145, 'n_estimators': 500, 'subsample': 1.0, 'min_child_weight': 5}. Best is trial 1 with value: -0.05704431929763076.\n",
      "[I 2024-04-07 13:52:16,311] Trial 2 finished with value: -0.05967539246698013 and parameters: {'max_depth': 9, 'learning_rate': 0.24129133929841357, 'n_estimators': 700, 'subsample': 0.9, 'min_child_weight': 6}. Best is trial 1 with value: -0.05704431929763076.\n",
      "[I 2024-04-07 13:52:16,740] Trial 3 finished with value: -0.0652410051602136 and parameters: {'max_depth': 3, 'learning_rate': 0.014483856214201587, 'n_estimators': 100, 'subsample': 0.5, 'min_child_weight': 4}. Best is trial 1 with value: -0.05704431929763076.\n",
      "[I 2024-04-07 13:52:17,153] Trial 4 finished with value: -0.060518154392224965 and parameters: {'max_depth': 2, 'learning_rate': 0.2526623291374936, 'n_estimators': 100, 'subsample': 0.30000000000000004, 'min_child_weight': 3}. Best is trial 1 with value: -0.05704431929763076.\n",
      "[I 2024-04-07 13:52:21,107] Trial 5 finished with value: -0.05924731647166417 and parameters: {'max_depth': 8, 'learning_rate': 0.04142548085012644, 'n_estimators': 300, 'subsample': 0.5, 'min_child_weight': 6}. Best is trial 1 with value: -0.05704431929763076.\n",
      "[I 2024-04-07 13:52:21,770] Trial 6 finished with value: -0.06731222797095224 and parameters: {'max_depth': 7, 'learning_rate': 0.3943111635940081, 'n_estimators': 100, 'subsample': 0.6, 'min_child_weight': 10}. Best is trial 1 with value: -0.05704431929763076.\n",
      "[I 2024-04-07 13:52:22,565] Trial 7 finished with value: -0.06037015674059028 and parameters: {'max_depth': 9, 'learning_rate': 0.06795242419645665, 'n_estimators': 100, 'subsample': 0.4, 'min_child_weight': 7}. Best is trial 1 with value: -0.05704431929763076.\n",
      "[I 2024-04-07 13:52:26,664] Trial 8 finished with value: -0.05609184545983277 and parameters: {'max_depth': 3, 'learning_rate': 0.010474072253045643, 'n_estimators': 1000, 'subsample': 0.9, 'min_child_weight': 2}. Best is trial 8 with value: -0.05609184545983277.\n",
      "[I 2024-04-07 13:52:30,166] Trial 9 finished with value: -0.058146343584263 and parameters: {'max_depth': 4, 'learning_rate': 0.11503588469850354, 'n_estimators': 700, 'subsample': 0.9, 'min_child_weight': 1}. Best is trial 8 with value: -0.05609184545983277.\n",
      "[I 2024-04-07 13:52:37,643] Trial 10 finished with value: -0.05750827213066689 and parameters: {'max_depth': 6, 'learning_rate': 0.027046092411000748, 'n_estimators': 1000, 'subsample': 0.7000000000000001, 'min_child_weight': 1}. Best is trial 8 with value: -0.05609184545983277.\n",
      "[I 2024-04-07 13:52:45,135] Trial 11 finished with value: -0.05701262883941467 and parameters: {'max_depth': 5, 'learning_rate': 0.010708627253198932, 'n_estimators': 1000, 'subsample': 1.0, 'min_child_weight': 9}. Best is trial 8 with value: -0.05609184545983277.\n",
      "[I 2024-04-07 13:52:49,599] Trial 12 finished with value: -0.05629540179513417 and parameters: {'max_depth': 3, 'learning_rate': 0.011032009113443732, 'n_estimators': 1000, 'subsample': 0.8, 'min_child_weight': 9}. Best is trial 8 with value: -0.05609184545983277.\n",
      "[I 2024-04-07 13:52:52,708] Trial 13 finished with value: -0.056569970818108065 and parameters: {'max_depth': 3, 'learning_rate': 0.024563369786050053, 'n_estimators': 800, 'subsample': 0.8, 'min_child_weight': 8}. Best is trial 8 with value: -0.05609184545983277.\n",
      "[I 2024-04-07 13:52:56,783] Trial 14 finished with value: -0.05622278755445742 and parameters: {'max_depth': 3, 'learning_rate': 0.010078917324857219, 'n_estimators': 900, 'subsample': 0.7000000000000001, 'min_child_weight': 10}. Best is trial 8 with value: -0.05609184545983277.\n",
      "[I 2024-04-07 13:52:59,671] Trial 15 finished with value: -0.05673320219912344 and parameters: {'max_depth': 3, 'learning_rate': 0.023080358373827735, 'n_estimators': 800, 'subsample': 0.7000000000000001, 'min_child_weight': 2}. Best is trial 8 with value: -0.05609184545983277.\n",
      "[I 2024-04-07 13:53:02,956] Trial 16 finished with value: -0.05878724617796745 and parameters: {'max_depth': 3, 'learning_rate': 0.1098184544627628, 'n_estimators': 900, 'subsample': 0.7000000000000001, 'min_child_weight': 4}. Best is trial 8 with value: -0.05609184545983277.\n",
      "[I 2024-04-07 13:53:04,823] Trial 17 finished with value: -0.06587117004001285 and parameters: {'max_depth': 8, 'learning_rate': 0.03291128196093804, 'n_estimators': 600, 'subsample': 0.1, 'min_child_weight': 10}. Best is trial 8 with value: -0.05609184545983277.\n",
      "[I 2024-04-07 13:53:07,447] Trial 18 finished with value: -0.05617201000257853 and parameters: {'max_depth': 2, 'learning_rate': 0.01671725499241759, 'n_estimators': 900, 'subsample': 0.9, 'min_child_weight': 7}. Best is trial 8 with value: -0.05609184545983277.\n",
      "[I 2024-04-07 13:53:09,093] Trial 19 finished with value: -0.05620529653407047 and parameters: {'max_depth': 2, 'learning_rate': 0.02079610381202874, 'n_estimators': 500, 'subsample': 0.9, 'min_child_weight': 7}. Best is trial 8 with value: -0.05609184545983277.\n",
      "[I 2024-04-07 13:53:12,421] Trial 20 finished with value: -0.05647693828794018 and parameters: {'max_depth': 2, 'learning_rate': 0.041739353978721604, 'n_estimators': 900, 'subsample': 1.0, 'min_child_weight': 5}. Best is trial 8 with value: -0.05609184545983277.\n",
      "[I 2024-04-07 13:53:14,268] Trial 21 finished with value: -0.056023440474106144 and parameters: {'max_depth': 2, 'learning_rate': 0.01680798376004162, 'n_estimators': 500, 'subsample': 0.9, 'min_child_weight': 7}. Best is trial 21 with value: -0.056023440474106144.\n",
      "[I 2024-04-07 13:53:15,759] Trial 22 finished with value: -0.056016701589095205 and parameters: {'max_depth': 2, 'learning_rate': 0.017640083858920422, 'n_estimators': 400, 'subsample': 0.8, 'min_child_weight': 7}. Best is trial 22 with value: -0.056016701589095205.\n",
      "[I 2024-04-07 13:53:17,628] Trial 23 finished with value: -0.056108341627224625 and parameters: {'max_depth': 2, 'learning_rate': 0.015101139466216973, 'n_estimators': 400, 'subsample': 0.8, 'min_child_weight': 8}. Best is trial 22 with value: -0.056016701589095205.\n",
      "[I 2024-04-07 13:53:20,298] Trial 24 finished with value: -0.05724849558260333 and parameters: {'max_depth': 7, 'learning_rate': 0.03398449937535924, 'n_estimators': 300, 'subsample': 0.8, 'min_child_weight': 8}. Best is trial 22 with value: -0.056016701589095205.\n",
      "[I 2024-04-07 13:53:22,432] Trial 25 finished with value: -0.05734019186536924 and parameters: {'max_depth': 4, 'learning_rate': 0.013142467092666432, 'n_estimators': 400, 'subsample': 0.6, 'min_child_weight': 6}. Best is trial 22 with value: -0.056016701589095205.\n",
      "[I 2024-04-07 13:53:27,386] Trial 26 finished with value: -0.05720628920719929 and parameters: {'max_depth': 6, 'learning_rate': 0.017279488335816193, 'n_estimators': 600, 'subsample': 1.0, 'min_child_weight': 4}. Best is trial 22 with value: -0.056016701589095205.\n",
      "[I 2024-04-07 13:53:29,055] Trial 27 finished with value: -0.05729975882410613 and parameters: {'max_depth': 2, 'learning_rate': 0.10388001130158937, 'n_estimators': 400, 'subsample': 0.9, 'min_child_weight': 7}. Best is trial 22 with value: -0.056016701589095205.\n",
      "[I 2024-04-07 13:53:30,044] Trial 28 finished with value: -0.056142270785724556 and parameters: {'max_depth': 2, 'learning_rate': 0.022419304609133706, 'n_estimators': 200, 'subsample': 0.8, 'min_child_weight': 5}. Best is trial 22 with value: -0.056016701589095205.\n",
      "[I 2024-04-07 13:53:31,650] Trial 29 finished with value: -0.05688390639510675 and parameters: {'max_depth': 2, 'learning_rate': 0.049754924840087034, 'n_estimators': 500, 'subsample': 0.6, 'min_child_weight': 3}. Best is trial 22 with value: -0.056016701589095205.\n",
      "[I 2024-04-07 13:53:36,535] Trial 30 finished with value: -0.057155983123006446 and parameters: {'max_depth': 5, 'learning_rate': 0.030803716546749453, 'n_estimators': 600, 'subsample': 0.9, 'min_child_weight': 2}. Best is trial 22 with value: -0.056016701589095205.\n",
      "[I 2024-04-07 13:53:37,992] Trial 31 finished with value: -0.05612069379869735 and parameters: {'max_depth': 2, 'learning_rate': 0.013945362034815636, 'n_estimators': 400, 'subsample': 0.8, 'min_child_weight': 8}. Best is trial 22 with value: -0.056016701589095205.\n",
      "[I 2024-04-07 13:53:39,368] Trial 32 finished with value: -0.05615394897495592 and parameters: {'max_depth': 2, 'learning_rate': 0.018354076494218215, 'n_estimators': 400, 'subsample': 1.0, 'min_child_weight': 9}. Best is trial 22 with value: -0.056016701589095205.\n",
      "[I 2024-04-07 13:53:40,586] Trial 33 finished with value: -0.05648103715405532 and parameters: {'max_depth': 2, 'learning_rate': 0.01308683418550539, 'n_estimators': 300, 'subsample': 0.8, 'min_child_weight': 8}. Best is trial 22 with value: -0.056016701589095205.\n",
      "[I 2024-04-07 13:53:44,143] Trial 34 finished with value: -0.05819403614104596 and parameters: {'max_depth': 9, 'learning_rate': 0.012574590892209575, 'n_estimators': 200, 'subsample': 0.9, 'min_child_weight': 6}. Best is trial 22 with value: -0.056016701589095205.\n",
      "[I 2024-04-07 13:53:45,843] Trial 35 finished with value: -0.0561579027272857 and parameters: {'max_depth': 2, 'learning_rate': 0.018057423457582253, 'n_estimators': 500, 'subsample': 0.7000000000000001, 'min_child_weight': 7}. Best is trial 22 with value: -0.056016701589095205.\n",
      "[I 2024-04-07 13:53:54,623] Trial 36 finished with value: -0.05713974324682954 and parameters: {'max_depth': 8, 'learning_rate': 0.014452466586201583, 'n_estimators': 700, 'subsample': 1.0, 'min_child_weight': 6}. Best is trial 22 with value: -0.056016701589095205.\n",
      "[I 2024-04-07 13:53:56,578] Trial 37 finished with value: -0.05791267246296642 and parameters: {'max_depth': 4, 'learning_rate': 0.02021048225725974, 'n_estimators': 500, 'subsample': 0.4, 'min_child_weight': 8}. Best is trial 22 with value: -0.056016701589095205.\n",
      "[I 2024-04-07 13:53:59,124] Trial 38 finished with value: -0.05880042806844941 and parameters: {'max_depth': 7, 'learning_rate': 0.010012878123152805, 'n_estimators': 200, 'subsample': 0.9, 'min_child_weight': 9}. Best is trial 22 with value: -0.056016701589095205.\n",
      "[I 2024-04-07 13:54:02,326] Trial 39 finished with value: -0.05784173929863219 and parameters: {'max_depth': 6, 'learning_rate': 0.027667019255729154, 'n_estimators': 300, 'subsample': 0.6, 'min_child_weight': 5}. Best is trial 22 with value: -0.056016701589095205.\n",
      "[I 2024-04-07 13:54:05,968] Trial 40 finished with value: -0.06433381105596445 and parameters: {'max_depth': 9, 'learning_rate': 0.20549535775706057, 'n_estimators': 400, 'subsample': 0.5, 'min_child_weight': 6}. Best is trial 22 with value: -0.056016701589095205.\n",
      "[I 2024-04-07 13:54:07,353] Trial 41 finished with value: -0.05617519143437777 and parameters: {'max_depth': 2, 'learning_rate': 0.014556119536153114, 'n_estimators': 400, 'subsample': 0.8, 'min_child_weight': 8}. Best is trial 22 with value: -0.056016701589095205.\n",
      "[I 2024-04-07 13:54:08,633] Trial 42 finished with value: -0.056093019892538884 and parameters: {'max_depth': 2, 'learning_rate': 0.0154796253442021, 'n_estimators': 400, 'subsample': 0.8, 'min_child_weight': 7}. Best is trial 22 with value: -0.056016701589095205.\n",
      "[I 2024-04-07 13:54:10,132] Trial 43 finished with value: -0.05613626965051159 and parameters: {'max_depth': 2, 'learning_rate': 0.015838975320235486, 'n_estimators': 500, 'subsample': 0.9, 'min_child_weight': 7}. Best is trial 22 with value: -0.056016701589095205.\n",
      "[I 2024-04-07 13:54:13,205] Trial 44 finished with value: -0.05719304166864161 and parameters: {'max_depth': 5, 'learning_rate': 0.011932146523421797, 'n_estimators': 600, 'subsample': 0.7000000000000001, 'min_child_weight': 7}. Best is trial 22 with value: -0.056016701589095205.\n",
      "[I 2024-04-07 13:54:14,395] Trial 45 finished with value: -0.057134384725490296 and parameters: {'max_depth': 2, 'learning_rate': 0.08506246607806896, 'n_estimators': 400, 'subsample': 0.8, 'min_child_weight': 6}. Best is trial 22 with value: -0.056016701589095205.\n",
      "[I 2024-04-07 13:54:16,292] Trial 46 finished with value: -0.05784164805092081 and parameters: {'max_depth': 3, 'learning_rate': 0.14919180004974358, 'n_estimators': 500, 'subsample': 1.0, 'min_child_weight': 9}. Best is trial 22 with value: -0.056016701589095205.\n",
      "[I 2024-04-07 13:54:17,232] Trial 47 finished with value: -0.059784744900934494 and parameters: {'max_depth': 2, 'learning_rate': 0.3681286854396239, 'n_estimators': 300, 'subsample': 0.8, 'min_child_weight': 2}. Best is trial 22 with value: -0.056016701589095205.\n",
      "[I 2024-04-07 13:54:19,495] Trial 48 finished with value: -0.05669826328789522 and parameters: {'max_depth': 3, 'learning_rate': 0.026066574227326902, 'n_estimators': 700, 'subsample': 0.7000000000000001, 'min_child_weight': 7}. Best is trial 22 with value: -0.056016701589095205.\n",
      "[I 2024-04-07 13:54:21,057] Trial 49 finished with value: -0.06217855044358004 and parameters: {'max_depth': 7, 'learning_rate': 0.020071729417286226, 'n_estimators': 200, 'subsample': 0.30000000000000004, 'min_child_weight': 1}. Best is trial 22 with value: -0.056016701589095205.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenTrial(number=22, state=TrialState.COMPLETE, values=[-0.056016701589095205], datetime_start=datetime.datetime(2024, 4, 7, 13, 53, 14, 269439), datetime_complete=datetime.datetime(2024, 4, 7, 13, 53, 15, 758795), params={'max_depth': 2, 'learning_rate': 0.017640083858920422, 'n_estimators': 400, 'subsample': 0.8, 'min_child_weight': 7}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'max_depth': CategoricalDistribution(choices=(2, 3, 4, 5, 6, 7, 8, 9)), 'learning_rate': FloatDistribution(high=0.5, log=True, low=0.01, step=None), 'n_estimators': IntDistribution(high=1000, log=False, low=100, step=100), 'subsample': FloatDistribution(high=1.0, log=False, low=0.1, step=0.1), 'min_child_weight': IntDistribution(high=10, log=False, low=1, step=1)}, trial_id=22, value=None)\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    param = {\"max_depth\":    trial.suggest_categorical('max_depth', [2, 3, 4, 5, 6, 7, 8, 9]),\n",
    "              \"learning_rate\": trial.suggest_float('learning_rate', 0.01, 0.5, log=True),\n",
    "              \"n_estimators\": trial.suggest_int('n_estimators', 100, 1000,step=100),\n",
    "              \"subsample\" : trial.suggest_float('subsample', 0.1, 1, step=0.1),\n",
    "              \"min_child_weight\" : trial.suggest_int('min_child_weight', 1, 10, step=1), \n",
    "              \"colsample_bytree\" : trial.suggest_float('subsample', 0.1, 1, step=0.1),\n",
    "            }\n",
    "    \n",
    "    clf = xgb.XGBRegressor(tree_method=\"hist\", enable_categorical=True, \n",
    "                                      objective='reg:absoluteerror', **param)\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(clf, X, dataset['Score'], cv=kfold, scoring='neg_mean_absolute_error')\n",
    "    score = np.mean(scores)\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.056016701589095205"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 2,\n",
       " 'learning_rate': 0.017640083858920422,\n",
       " 'n_estimators': 400,\n",
       " 'subsample': 0.8,\n",
       " 'min_child_weight': 7}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.017640083858920422,\n",
       "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "             min_child_weight=7, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=400, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.017640083858920422,\n",
       "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "             min_child_weight=7, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=400, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.017640083858920422,\n",
       "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "             min_child_weight=7, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=400, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = xgb.XGBRegressor(tree_method=\"hist\", enable_categorical=True, \n",
    "                                      objective='reg:squarederror', **study.best_params)\n",
    "clf.fit(X, dataset['Score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred = cross_val_predict(clf, X, dataset['Score'], cv=X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_with_scores = dataset.copy(deep=True)\n",
    "dataset_with_scores['Pred_Score'] = model_pred\n",
    "dataset_with_scores['Pred_Error'] = dataset_with_scores.Score - dataset_with_scores.Pred_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_with_scores = dataset_with_scores[['Pred_Score', 'Pred_Error'] + list(dataset.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.00519\n",
      "RMSE = 0.07203\n",
      "MAE = 0.05594\n"
     ]
    }
   ],
   "source": [
    "final_mse = np.power(dataset_with_scores.Pred_Score - dataset_with_scores.Score, 2).mean()\n",
    "print(f\"MSE = {np.round(final_mse, 5)}\")\n",
    "print(f\"RMSE = {np.round(np.sqrt(final_mse), 5)}\")\n",
    "final_mae = abs(dataset_with_scores.Pred_Score - dataset_with_scores.Score).mean()\n",
    "print(f\"MAE = {np.round(final_mae, 5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf, open(\"model_data/xgb_model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_with_scores.to_csv(\"data/dataset_with_preds.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_3.8.18",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
